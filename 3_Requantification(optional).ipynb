{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0420ca96",
   "metadata": {},
   "source": [
    "### `Re-quantification`\n",
    "\n",
    "The re-quantification consists of 7 steps\n",
    "\n",
    "![Re-quantification.png](images/Re-quantification.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyopenms import *\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1550692a",
   "metadata": {},
   "source": [
    "#### `1) Split consensus`\n",
    "\n",
    " Split the ConsensusMap into features that have no missing values, and features that have at least one missing value; requantify only the missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1edb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "interim= os.path.join(\"results\", \"interim\")\n",
    "path = os.path.join(interim, \"Requantification\")\n",
    "if not os.path.exists(path): # if it doesn't exist\n",
    "    os.mkdir(path) # create a path directory\n",
    "    \n",
    "# split ConsensusMap\n",
    "consensus_map = ConsensusMap()\n",
    "ConsensusXMLFile().load(os.path.join(interim, \"Preprocessing\", \"consensus\" + \".consensusXML\"), consensus_map)\n",
    "\n",
    "headers = consensus_map.getColumnHeaders()\n",
    "\n",
    "complete = ConsensusMap(consensus_map)\n",
    "complete.clear(False)\n",
    "missing = ConsensusMap(consensus_map)\n",
    "missing.clear(False)\n",
    "\n",
    "for cf in consensus_map:\n",
    "    if len(cf.getFeatureList()) < len(headers): #missing values\n",
    "        missing.push_back(cf)\n",
    "    else:\n",
    "        complete.push_back(cf) #no missing values\n",
    "\n",
    "ConsensusXMLFile().store(os.path.join(path, \"consensus_complete\" + \".consensusXML\"), complete)\n",
    "ConsensusXMLFile().store(os.path.join(path, \"consensus_missing\" + \".consensusXML\"), missing)\n",
    "\n",
    "# get intensities as a DataFrame\n",
    "result = missing.get_df()\n",
    "result= result.reset_index()\n",
    "result= result.drop(columns= [\"sequence\"])\n",
    "# store as tsv file\n",
    "result.to_csv(os.path.join(path, \"FeatureMatrixNaN.tsv\"), sep = \"\\t\", index = False)\n",
    "result\n",
    "\n",
    "# reconstruct complete FeatureMaps\n",
    "consensus_map = ConsensusMap()\n",
    "ConsensusXMLFile().load(os.path.join(path, \"consensus_complete\" + \".consensusXML\"), consensus_map)\n",
    "\n",
    "featurexml_files= glob.glob(os.path.join(interim, \"Preprocessing\", 'MapAligned_*.featureXML'))\n",
    "feature_maps = []\n",
    "for featurexml_file in featurexml_files:\n",
    "    fmap = FeatureMap()\n",
    "    FeatureXMLFile().load(featurexml_file, fmap)\n",
    "    feature_maps.append(fmap)\n",
    "\n",
    "to_keep_ids = [item for sublist in [[feature.getUniqueId() for feature in cf.getFeatureList()] for cf in consensus_map] for item in sublist]\n",
    "\n",
    "for fm in feature_maps:\n",
    "    fm_filterd = FeatureMap(fm)\n",
    "    fm_filterd.clear(False)\n",
    "    for f in fm:\n",
    "        if f.getUniqueId() in to_keep_ids:\n",
    "            fm_filterd.push_back(f)\n",
    "    FeatureXMLFile().store(os.path.join(path, \"Complete_\" + os.path.basename(fm_filterd.getMetaValue(\"spectra_data\")[0].decode())[7:-4] + \"featureXML\"), fm_filterd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c1520f",
   "metadata": {},
   "source": [
    "#### `2) FeatureFinderMetaboIdent: re-quantify`\n",
    "This algorithm detects and extracts MS1 data that match the feature list in the metabolite identification table.\n",
    "\n",
    "###### Documentation: https://abibuilder.informatik.uni-tuebingen.de/archive/openms/Documentation/nightly/html/UTILS_FeatureFinderMetaboIdent.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `2) (i) Create a library of metabolites`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abbdf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the feature matrix tsv table and keep only the columns: RT, mz and charge\n",
    "DF_features = pd.read_csv(os.path.join(path, \"FeatureMatrixNaN.tsv\"), sep=\"\\t\")\n",
    "DF_features = DF_features[[\"RT\",\"mz\", \"charge\"]]\n",
    "\n",
    "DF_features= DF_features.rename(columns={ \"charge\":\"Charge\", \"mz\": \"Mass\", \"RT\": \"RetentionTime\"})\n",
    "\n",
    "DF_features[\"Charge\"]= DF_features[\"Charge\"].astype(str)\n",
    "DF_features[\"Mass\"]= DF_features[\"Mass\"].astype(float)\n",
    "\n",
    "#For positive ionisation: comment this for negative ESI\n",
    "\n",
    "for ind in DF_features.index:\n",
    "    if DF_features[\"Charge\"][ind] == \"0\":\n",
    "        DF_features.loc[ind, \"Mass\"]= DF_features.loc[ind,\"Mass\"]- 1.007825\n",
    "        DF_features.loc[ind, \"Charge\"]= \"+1\"\n",
    "    if DF_features[\"Charge\"][ind] == \"1\":\n",
    "        DF_features.loc[ind, \"Mass\"]= DF_features.loc[ind,\"Mass\"]- 1.007825\n",
    "        DF_features.loc[ind, \"Charge\"]= \"+\" + DF_features.loc[ind,\"Charge\"]\n",
    "    if DF_features[\"Charge\"][ind] == \"2\":\n",
    "        DF_features.loc[ind, \"Mass\"]= (DF_features.loc[ind,\"Mass\"]*2)- 2.015650\n",
    "        DF_features.loc[ind, \"Charge\"]= \"+\" + DF_features.loc[ind,\"Charge\"]\n",
    "    if DF_features[\"Charge\"][ind] == \"3\":\n",
    "        DF_features.loc[ind, \"Mass\"]= (DF_features.loc[ind,\"Mass\"]*3)- 3.023475\n",
    "        DF_features.loc[ind, \"Charge\"]= \"+\" + DF_features.loc[ind,\"Charge\"]\n",
    "\n",
    "DF_features[\"CompoundName\"] = np.arange(len(DF_features))\n",
    "DF_features[\"CompoundName\"] = \"feature_\" + DF_features[\"CompoundName\"].astype(str)\n",
    "DF_features[\"SumFormula\"] = \" \"\n",
    "DF_features[\"RetentionTimeRange\"]= \"0\"\n",
    "DF_features[\"IsoDistribution\"]= \"0\"\n",
    "DF_features= DF_features[[\"CompoundName\",\"SumFormula\", \"Mass\",\"Charge\",\"RetentionTime\",\"RetentionTimeRange\", \"IsoDistribution\"]]\n",
    "DF_features.to_csv(os.path.join(path, \"MetaboliteIdentification.tsv\"), sep=\"\\t\", index= None)\n",
    "DF_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For negative ionisation: uncomment this for negative ESI\n",
    "    # for ind in DF_features.index:\n",
    "    #     if DF_features[\"Charge\"][ind] == \"0\":\n",
    "    #         DF_features.loc[ind, \"Mass\"]= DF_features.loc[ind,\"Mass\"]+ 1.007825\n",
    "    #     if DF_features[\"Charge\"][ind] == \"1\":\n",
    "    #         DF_features.loc[ind, \"Mass\"]= DF_features.loc[ind,\"Mass\"]+ 1.007825\n",
    "    #     if DF_features[\"Charge\"][ind] == \"2\":\n",
    "    #         DF_features.loc[ind, \"Mass\"]= (DF_features.loc[ind,\"Mass\"]*2)+ 2.015650\n",
    "    #     if DF_features[\"Charge\"][ind] == \"3\":\n",
    "    #         DF_features.loc[ind, \"Mass\"]= (DF_features.loc[ind,\"Mass\"]*3)+ 3.023475\n",
    "    # DF_features[\"Charge\"]= DF_features[\"Charge\"].astype(str)\n",
    "    # for ind in DF_features.index:\n",
    "    #     if DF_features[\"Charge\"][ind] == \"0\":\n",
    "    #         DF_features.loc[ind, \"Charge\"]= \"-1\"\n",
    "    #     if DF_features[\"Charge\"][ind] == \"1\":\n",
    "    #         DF_features.loc[ind, \"Charge\"]= \"-\" + DF_features.loc[ind,\"Charge\"]\n",
    "    #     if DF_features[\"Charge\"][ind] == \"2\":\n",
    "    #         DF_features.loc[ind, \"Charge\"]= \"-\" + DF_features.loc[ind,\"Charge\"]\n",
    "    #     if DF_features[\"Charge\"][ind] == \"3\":\n",
    "    #         DF_features.loc[ind, \"Charge\"]= \"-\" + DF_features.loc[ind,\"Charge\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b01a379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# read tsv file and create list of FeatureFinderMetaboIdentCompound\n",
    "def metaboTableFromFile(path_to_library_file):\n",
    "    metaboTable = []\n",
    "    with open(path_to_library_file, \"r\") as tsv_file:\n",
    "        tsv_reader = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "        next(tsv_reader) # skip header\n",
    "        for row in tsv_reader:\n",
    "            metaboTable.append(FeatureFinderMetaboIdentCompound(\n",
    "                row[0], # name\n",
    "                row[1], # sum formula\n",
    "                float(row[2]), # mass\n",
    "                [int(charge) for charge in row[3].split(\",\")], # charges\n",
    "                [float(rt) for rt in row[4].split(\",\")], # RTs\n",
    "                [float(rt_range) for rt_range in row[5].split(\",\")], # RT ranges\n",
    "                [float(iso_distrib) for iso_distrib in row[6].split(\",\")] # isotope distributions\n",
    "            ))\n",
    "    return metaboTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `2) (ii) Requantify mzML files`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a716aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_mzml_files=sorted(glob.glob(os.path.join(interim, 'Preprocessing', 'MapAligned_*.mzML')))\n",
    "\n",
    "# load ms data from mzML file into MSExperiment\n",
    "for mzml_file in input_mzml_files:\n",
    "    spectra = MSExperiment()\n",
    "    MzMLFile().load(mzml_file, spectra)\n",
    "\n",
    "    # create FeatureFinderAlgorithmMetaboIdent and assign ms data\n",
    "    ffmid = FeatureFinderAlgorithmMetaboIdent()\n",
    "    ffmid.setMSData(spectra)\n",
    "\n",
    "    params = ffmid.getParameters()\n",
    "    params[b\"extract:mz_window\"] = 10.0 \n",
    "    params[b\"detect:peak_width\"] = 60.0  #adjust for wide peaks\n",
    "    ffmid.setParameters(params)\n",
    "    # FeatureMap to store results\n",
    "    fm = FeatureMap()\n",
    "\n",
    "    # run the FeatureFinderMetaboIdent with the metabo_table and store results in fm\n",
    "    metabo_table = metaboTableFromFile(os.path.join(path, \"MetaboliteIdentification.tsv\"))\n",
    "    ffmid.run(metabo_table, fm, String(mzml_file))\n",
    "    # set number of mass traces (for SIRIUS)\n",
    "    fm_include_mass_traces = FeatureMap(fm)\n",
    "    fm_include_mass_traces.clear(False)\n",
    "    for feature in fm:\n",
    "        feature.setMetaValue(\"num_of_masstraces\", params[b\"extract:n_isotopes\"])\n",
    "        fm_include_mass_traces.push_back(feature)\n",
    "    fm = fm_include_mass_traces\n",
    "    \n",
    "    # save FeatureMap to file\n",
    "    ff_file = os.path.join(path, \"FFMID_\" + os.path.basename(mzml_file)[11:-5] +\".featureXML\")\n",
    "    FeatureXMLFile().store(ff_file, fm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aadcf67",
   "metadata": {},
   "source": [
    "#### `4) Merge Feature maps`\n",
    "\n",
    "Merge complete FeatureMaps from FFM with requantified FeatureMaps from FFMID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b30e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for complete_map in sorted(glob.glob(os.path.join(path, \"Complete_*.featureXML\"))):\n",
    "    for requant_map in sorted(glob.glob(os.path.join(path, \"FFMID_*.featureXML\"))):\n",
    "        if os.path.basename(complete_map)[9:] == os.path.basename(requant_map)[6:]:\n",
    "            fm_ffm = FeatureMap()\n",
    "            FeatureXMLFile().load(complete_map, fm_ffm)\n",
    "            fm_ffmid = FeatureMap()\n",
    "            FeatureXMLFile().load(requant_map, fm_ffmid)\n",
    "            for f in fm_ffmid:\n",
    "                fm_ffm.push_back(f)\n",
    "            fm_ffm.setUniqueIds()\n",
    "            FeatureXMLFile().store(os.path.join(path, \"Merged_\" + os.path.basename(complete_map)[9:]), fm_ffm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e58d2c",
   "metadata": {},
   "source": [
    "#### `5) Metabolite adduct decharger` \n",
    "\n",
    "For each peak, this algorithm reconstructs neutral masses by enumerating all possible adducts with matching charge. Here, we do not save the file with neutral masses, but only the feature files that contain adduct annotations. You can add the list of adduct for the algorithm to parse through. SIRIUS, an algorithm that is later used, is only able to compute singly charged adducts so charges higher than 1 are filtered out. Use adduct list: [b\"H-1:-:1\", b\"H-2O-1:0:0.05\", b\"CH2O2:0:0.5\"] for negative mode.\n",
    "\n",
    "###### Documentation: https://abibuilder.informatik.uni-tuebingen.de/archive/openms/Documentation/nightly/html/UTILS_MetaboliteAdductDecharger.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b17bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_feature_files= sorted(glob.glob(os.path.join(path, \"Merged_*.featureXML\")))\n",
    "\n",
    "for filename in input_feature_files:\n",
    "        feature_map = FeatureMap()    \n",
    "        FeatureXMLFile().load(filename, feature_map)\n",
    "        mfd = MetaboliteFeatureDeconvolution()\n",
    "        mdf_par = mfd.getDefaults()\n",
    "        mdf_par.setValue(\"potential_adducts\", [b\"H:+:0.4\",b\"Na:+:0.2\",b\"NH4:+:0.2\", b\"H-1O-1:+:0.1\", b\"H-3O-2:+:0.1\"])\n",
    "        mdf_par.setValue(\"charge_min\", 1, \"Minimal possible charge\")\n",
    "        mdf_par.setValue(\"charge_max\", 1, \"Maximal possible charge\")\n",
    "        mdf_par.setValue(\"charge_span_max\", 1)\n",
    "        mdf_par.setValue(\"max_neutrals\", 1)\n",
    "        mfd.setParameters(mdf_par)\n",
    "        feature_map_MFD = FeatureMap()\n",
    "        cons_map0 = ConsensusMap()\n",
    "        cons_map1 = ConsensusMap()\n",
    "        mfd.compute(feature_map, feature_map_MFD, cons_map0, cons_map1)\n",
    "        featurefile = os.path.join(path, \"MFD_\" + os.path.basename(filename)[7:])\n",
    "        FeatureXMLFile().store(featurefile, feature_map_MFD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fbed16",
   "metadata": {},
   "source": [
    "Display in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf2f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_feature_files = glob.glob(os.path.join(path, \"MFD_*.featureXML\"))\n",
    "\n",
    "path = os.path.join(\"results\", \"features\")\n",
    "if not os.path.exists(path): # if it doesn't exist\n",
    "    os.mkdir(path) # create a path directory\n",
    "\n",
    "for filename in input_feature_files:\n",
    "    fmap = FeatureMap()\n",
    "    FeatureXMLFile().load(filename, fmap)\n",
    "    DF= fmap.get_df(export_peptide_identifications=False)\n",
    "    for f in fmap:\n",
    "            if f.metaValueExists(\"dc_charge_adducts\"):\n",
    "                DF[\"adduct\"] = [f.getMetaValue(\"dc_charge_adducts\") for f in fmap]\n",
    "    feature_csv= os.path.join(path, \"features_\" + os.path.basename(filename)[4:-10] +\"csv\")\n",
    "    DF.to_csv(feature_csv)\n",
    "print(\"example:\", os.path.basename(filename))\n",
    "display(DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c91ca40",
   "metadata": {},
   "source": [
    "#### `6) IDMapper` \n",
    "\n",
    "Introduce the features to a protein identification file (idXML)- the only way to annotate MS2 spectra for GNPS FBMN  (of later importance)\n",
    "\n",
    "###### Documentation: https://abibuilder.informatik.uni-tuebingen.de/archive/openms/Documentation/nightly/html/TOPP_IDMapper.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c30b864",
   "metadata": {},
   "outputs": [],
   "source": [
    "interim= os.path.join(\"results\", \"interim\")\n",
    "path= os.path.join(interim, \"Requantification\")\n",
    "input_feature_files = sorted(glob.glob(os.path.join(path, \"MFD_*.featureXML\")))\n",
    "\n",
    "feature_maps = []\n",
    "for featurexml_file in input_feature_files:\n",
    "    fmap = FeatureMap()\n",
    "    FeatureXMLFile().load(featurexml_file, fmap)\n",
    "    feature_maps.append(fmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ebccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_centroid_rt= False\n",
    "use_centroid_mz= True\n",
    "protein_ids = []\n",
    "peptide_ids= []\n",
    "\n",
    "mapper = IDMapper()\n",
    "\n",
    "input_mzml_files= sorted(glob.glob(os.path.join(interim, 'Preprocessing', \"MapAligned_*.mzML\")))\n",
    "\n",
    "for filename in input_mzml_files:\n",
    "    exp = MSExperiment()\n",
    "    MzMLFile().load(filename, exp)\n",
    "    for fmap in feature_maps:\n",
    "        peptide_ids = []\n",
    "        protein_ids = []\n",
    "        if os.path.basename(fmap.getMetaValue(\"spectra_data\")[0].decode())[7:] == os.path.basename(filename)[11:]:\n",
    "            mapper.annotate(fmap, peptide_ids, protein_ids, use_centroid_rt, use_centroid_mz, exp)\n",
    "            featureidx_file = os.path.join(path, \"IDMapper_\" + os.path.basename(filename)[11:-4] +\"featureXML\")\n",
    "            FeatureXMLFile().store(featureidx_file, fmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80571ca1",
   "metadata": {},
   "source": [
    "#### `7) FeatureGroupingAlgorithmKD `\n",
    "\n",
    "Feature linker clusters the feature information (from single files) into a ConsensusFeature, linking features from different files together, which have a smiliar m/z and rt (no MS2 data).\n",
    "\n",
    "###### Documentation: https://abibuilder.informatik.uni-tuebingen.de/archive/openms/Documentation/release/latest/html/TOPP_FeatureLinkerUnlabeledKD.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f57ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "interim= os.path.join(\"results\", \"interim\")\n",
    "path= os.path.join(interim, \"Requantification\")\n",
    "\n",
    "input_feature_files = sorted(glob.glob(os.path.join(path, \"IDMapper_*.featureXML\")))\n",
    "\n",
    "feature_maps = []\n",
    "for featurexml_file in input_feature_files:\n",
    "    fmap = FeatureMap()\n",
    "    FeatureXMLFile().load(featurexml_file, fmap)\n",
    "    feature_maps.append(fmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3034793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_grouper = FeatureGroupingAlgorithmKD()\n",
    "\n",
    "consensus_map = ConsensusMap()\n",
    "file_descriptions = consensus_map.getColumnHeaders()\n",
    "\n",
    "for i, feature_map in enumerate(feature_maps):\n",
    "    file_description = file_descriptions.get(i, ColumnHeader())\n",
    "    file_description.filename = os.path.basename(feature_map.getMetaValue(\"spectra_data\")[0].decode())[7:]\n",
    "    file_description.size = feature_map.size()\n",
    "    file_descriptions[i] = file_description\n",
    "\n",
    "feature_grouper.group(feature_maps, consensus_map)\n",
    "consensus_map.setUniqueIds()\n",
    "consensus_map.setColumnHeaders(file_descriptions)\n",
    "\n",
    "\n",
    "Consensus_file= os.path.join(path, \"consensus\" + \".consensusXML\")\n",
    "ConsensusXMLFile().store(Consensus_file, consensus_map)\n",
    "\n",
    "# get intensities as a DataFrame\n",
    "df = consensus_map.get_df()\n",
    "for cf in consensus_map:\n",
    "    if cf.metaValueExists(\"best ion\"):\n",
    "        df[\"adduct\"] = [cf.getMetaValue(\"best ion\") for cf in consensus_map]\n",
    "        break\n",
    "df[\"feature_ids\"] = [[handle.getUniqueId() for handle in cf.getFeatureList()] for cf in consensus_map]\n",
    "df= df.reset_index()\n",
    "df= df.drop(columns= [\"sequence\"])\n",
    "df= df.rename(columns={\"RT\": \"RT(s)\", \"mz\" :\"m/z\"})\n",
    "# store as tsv file\n",
    "df.to_csv(os.path.join(\"results\", \"features\", \"FeatureMatrix_Requantified.tsv\"), sep = \"\\t\", index = False)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyopenms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edde62aa2661007f0756e9790e7a328c288a583bf6ce768a355147dac67c8db8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
