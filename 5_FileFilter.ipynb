{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Determination of memory status is not supported on this \n",
      " platform, measuring for memoryleaks will never fail\n"
     ]
    }
   ],
   "source": [
    "from pyopenms import *\n",
    "import pyopenms as pms\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConsensusMapDF(ConsensusMap):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def get_intensity_df(self):\n",
    "        labelfree = self.getExperimentType() == \"label-free\"\n",
    "        filemeta = self.getColumnHeaders()  # type: dict[int, ColumnHeader]\n",
    "        labels = list(set([header.label for header in\n",
    "                           filemeta.values()]))  # TODO could be more efficient. Do we require same channels in all files?\n",
    "        files = list(set([header.filename for header in filemeta.values()]))\n",
    "        label_to_idx = {k: v for v, k in enumerate(labels)}\n",
    "        file_to_idx = {k: v for v, k in enumerate(files)}\n",
    "\n",
    "        def gen(cmap: ConsensusMap, fun):\n",
    "            for f in cmap:\n",
    "                yield from fun(f)\n",
    "\n",
    "        if not labelfree:\n",
    "            # TODO write two functions for LF and labelled. One has only one channel, the other has only one file per CF\n",
    "            def extractRowBlocksChannelWideFileLong(f: ConsensusFeature):\n",
    "                subfeatures = f.getFeatureList()  # type: list[FeatureHandle]\n",
    "                filerows = defaultdict(lambda: [0] * len(labels))  # TODO use numpy array?\n",
    "                for fh in subfeatures:\n",
    "                    header = filemeta[fh.getMapIndex()]\n",
    "                    row = filerows[header.filename]\n",
    "                    row[label_to_idx[header.label]] = fh.getIntensity()\n",
    "                return (f.getUniqueId(), filerows)\n",
    "\n",
    "            def extractRowsChannelWideFileLong(f: ConsensusFeature):\n",
    "                uniqueid, rowdict = extractRowBlocksChannelWideFileLong(f)\n",
    "                for file, row in rowdict.items():\n",
    "                    row.append(file)\n",
    "                    yield tuple([uniqueid] + row)\n",
    "\n",
    "            if len(labels) == 1:\n",
    "                labels[0] = \"intensity\"\n",
    "            dtypes = [('id', np.dtype('uint64'))] + list(zip(labels, ['f'] * len(labels)))\n",
    "            dtypes.append(('file', 'U300'))\n",
    "            # For TMT we know that every feature can only be from one file, since feature = PSM\n",
    "            #cnt = 0\n",
    "            #for f in self:\n",
    "            #    cnt += f.size()\n",
    "\n",
    "            intyarr = np.fromiter(iter=gen(self, extractRowsChannelWideFileLong), dtype=dtypes, count=self.size())\n",
    "            return pd.DataFrame(intyarr).set_index('id')\n",
    "        else:\n",
    "            # Specialized for LabelFree which has to have only one channel\n",
    "            def extractRowBlocksChannelLongFileWideLF(f: ConsensusFeature):\n",
    "                subfeatures = f.getFeatureList()  # type: list[FeatureHandle]\n",
    "                row = [0.] * len(files)  # TODO use numpy array?\n",
    "                for fh in subfeatures:\n",
    "                    header = filemeta[fh.getMapIndex()]\n",
    "                    row[file_to_idx[header.filename]] = fh.getIntensity()\n",
    "                yield tuple([f.getUniqueId()] + row)\n",
    "\n",
    "            dtypes = [('id', np.dtype('uint64'))] + list(zip(files, ['f'] * len(files)))\n",
    "            # cnt = self.size()*len(files) # TODO for this to work, we would need to fill with NAs for CFs that do not go over all files\n",
    "            cnt = self.size()\n",
    "\n",
    "            intyarr = np.fromiter(iter=gen(self, extractRowBlocksChannelLongFileWideLF), dtype=dtypes, count=cnt)\n",
    "            return pd.DataFrame(intyarr).set_index('id')\n",
    "\n",
    "    def get_metadata_df(self):\n",
    "        def gen(cmap: ConsensusMap, fun):\n",
    "            for f in cmap:\n",
    "                yield from fun(f)\n",
    "\n",
    "        def extractMetaData(f: ConsensusFeature):\n",
    "            # subfeatures = f.getFeatureList()  # type: list[FeatureHandle]\n",
    "            pep = f.getPeptideIdentifications()  # type: list[PeptideIdentification]\n",
    "            if len(pep) != 0:\n",
    "                hits = pep[0].getHits()\n",
    "                if len(hits) != 0:\n",
    "                    besthit = hits[0]  # type: PeptideHit\n",
    "                    # TODO what else\n",
    "                    yield f.getUniqueId(), besthit.getSequence().toString(), f.getCharge(), f.getRT(), f.getMZ(), f.getQuality()\n",
    "                else:\n",
    "                    yield f.getUniqueId(), None, f.getCharge(), f.getRT(), f.getMZ(), f.getQuality()\n",
    "            else:\n",
    "                yield f.getUniqueId(), None, f.getCharge(), f.getRT(), f.getMZ(), f.getQuality()\n",
    "\n",
    "        cnt = self.size()\n",
    "\n",
    "        mddtypes = [('id', np.dtype('uint64')), ('sequence', 'U200'), ('charge', 'f'), ('RT', 'f'), ('mz', 'f'),\n",
    "                    ('quality', 'f')]\n",
    "        mdarr = np.fromiter(iter=gen(self, extractMetaData), dtype=mddtypes, count=cnt)\n",
    "        return pd.DataFrame(mdarr).set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_consensus= \"results/consensus/interim/consensus.consensusXML\"\n",
    "cmap = ConsensusMap()\n",
    "ConsensusXMLFile().load(input_consensus, cmap)\n",
    "new_map= ConsensusMap(cmap)\n",
    "new_map.clear(False)\n",
    "for f in cmap:\n",
    "    if f.getPeptideIdentifications() !=[]:\n",
    "        print(f.getPeptideIdentifications())\n",
    "        new_map.push_back(f)\n",
    "        \n",
    "Consensus_file= os.path.join(\"results\", \"\", \"consensus\", \"\", 'filtered_pyopenms' + \".consensusXML\")\n",
    "ConsensusXMLFile().store(Consensus_file, new_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_descriptions = new_map.getColumnHeaders()\n",
    "file_description = file_descriptions.get(i, ColumnHeader())\n",
    "file_description.size = new_map.size()\n",
    "file_description.unique_id = new_map.getUniqueId()\n",
    "file_descriptions[i] = file_description\n",
    "\n",
    "consensus_map= ConsensusMapDF()\n",
    "for f in new_map:\n",
    "    consensus_map.push_back(f)\n",
    "    # get intensities as a DataFrame\n",
    "    consensus_map.setColumnHeaders(file_descriptions)\n",
    "\n",
    "    intensities = consensus_map.get_intensity_df()\n",
    "\n",
    "    # get meta data as DataFrame\n",
    "    meta_data = consensus_map.get_metadata_df()[['RT', 'mz', \"charge\"]]\n",
    "\n",
    "    # you can concatenate these two for a \"result\" DataFrame\n",
    "    result = pd.concat([meta_data, intensities], axis=1)\n",
    "\n",
    "    # if you don't need labeled index, remove it (and/or save with index = False)\n",
    "    result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # store as tsv file\n",
    "    result.to_csv('results/consensus/Filtered_Consensus.tsv', sep = '\\t', index = False)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edde62aa2661007f0756e9790e7a328c288a583bf6ce768a355147dac67c8db8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
