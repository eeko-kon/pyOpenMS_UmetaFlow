{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Determination of memory status is not supported on this \n",
      " platform, measuring for memoryleaks will never fail\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from pyteomics import mgf, auxiliary\n",
    "from pyopenms import *\n",
    "import pyteomics\n",
    "from pyteomics import mztab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= os.path.join(\"results\", \"interim\", \"annotations\")\n",
    "isExist= os.path.exists(path)\n",
    "if not isExist:\n",
    "    os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First,import the feature table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureMatrix= os.path.join(\"results\", \"features\", \"FeatureMatrix.tsv\")\n",
    "DF_features= pd.read_csv(FeatureMatrix, sep=\"\\t\")\n",
    "DF_features= DF_features.drop(columns=[\"charge\", \"quality\"])\n",
    "DF_features= DF_features.fillna(0)\n",
    "DF_features[\"feature_ids\"]= DF_features[\"feature_ids\"].str.replace(r\"[\", \"\")\n",
    "DF_features[\"feature_ids\"]= DF_features[\"feature_ids\"].str.replace(r\"]\", \"\")\n",
    "\n",
    "for i, rows in DF_features.iterrows():\n",
    "    DF_features[\"feature_ids\"][i]= DF_features[\"feature_ids\"][i].split(\",\")\n",
    "DF_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `1) SIRIUS and CSI:FingerID annotations`\n",
    "\n",
    "Create a matrix with all SIRIUS and CSI:FingerID formula and structural predictions, only choose #1 rankings predictions and combine the dataframes to annotate formula and structural predictions according to RT and mz:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_formulas will likely contain duplicate formulas that could be either isomeric, isobaric compounds, or identical compounds (with identical RT and mz). Here, we want to collapse the identical, repeating compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_formulas= glob.glob(os.path.join(\"results\", \"SiriusCSI\", \"formulas_*.tsv\"))\n",
    "DF_SIRIUS = pd.DataFrame()\n",
    "list_of_df=[]\n",
    "for csv in input_formulas:\n",
    "    df= pd.read_csv(csv, sep=\"\\t\", index_col=\"Unnamed: 0\")\n",
    "    s= df[\"opt_global_rank\"]\n",
    "    pd.to_numeric(s)\n",
    "    df= df.loc[df[\"opt_global_rank\"]==1]\n",
    "    df= df.rename(columns={\"opt_global_featureId\":\"featureId\"})\n",
    "    df= df.drop(columns=df.filter(regex=fr\"Score\").columns)\n",
    "    df= df.drop(columns= df.filter(regex=fr\"opt\").columns)\n",
    "    df=df.reset_index()\n",
    "    list_of_df.append(df)\n",
    "DF_SIRIUS= pd.concat(list_of_df,ignore_index=True)\n",
    "DF_SIRIUS= DF_SIRIUS.drop(columns=\"index\")\n",
    "DF_SIRIUS= DF_SIRIUS.rename(columns= {\"chemical_formula\": \"formulas\", \"exp_mass_to_charge\": \"mz\", \"retention_time\": \"RT\"})\n",
    "DF_SIRIUS[\"featureId\"]= DF_SIRIUS[\"featureId\"].str.replace(r\"id_\", \"\")\n",
    "DF_SIRIUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for structral predictions (remove duplicates with the same inchi_keys, which means they represent the same structure):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_structures= glob.glob(os.path.join(\"results\", \"SiriusCSI\", \"structures_*.tsv\"))\n",
    "DF_CSI = pd.DataFrame()\n",
    "list_of_df=[]\n",
    "for csv in input_structures:\n",
    "    df= pd.read_csv(csv, sep=\"\\t\", index_col=\"Unnamed: 0\")\n",
    "    s= df[\"opt_global_rank\"]\n",
    "    pd.to_numeric(s)\n",
    "    df= df.loc[df[\"opt_global_rank\"]==1]\n",
    "    df= df.rename(columns={\"opt_global_featureId\":\"featureId\"})\n",
    "    df= df.drop(columns=df.filter(regex=fr\"Score\").columns)\n",
    "    df= df.drop(columns= df.filter(regex=fr\"opt\").columns)\n",
    "    df=df.reset_index()\n",
    "    list_of_df.append(df)\n",
    "DF_CSI= pd.concat(list_of_df,ignore_index=True)\n",
    "DF_CSI= DF_CSI.drop(columns=\"index\")\n",
    "DF_CSI= DF_CSI.rename(columns= {\"chemical_formula\": \"formulas\", \"exp_mass_to_charge\": \"mz\", \"retention_time\": \"RT\", \"description\":\"name\"})\n",
    "DF_CSI[\"featureId\"]= DF_CSI[\"featureId\"].str.replace(r\"id_\", \"\")\n",
    "DF_CSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotate the formulas and structural predictions to the feature matrix according to SIRIUS and CSI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_features.insert(0, \"SIRIUS_predictions\", \"\")\n",
    "\n",
    "for i, id in zip(DF_features.index, DF_features[\"feature_ids\"]):\n",
    "    hits = []\n",
    "    for name, Pred_id in zip(DF_SIRIUS[\"formulas\"], DF_SIRIUS[\"featureId\"]): \n",
    "        if Pred_id in id:\n",
    "            hit = f\"{name}\"\n",
    "            if hit not in hits:\n",
    "                hits.append(hit)\n",
    "    DF_features[\"SIRIUS_predictions\"][i] = \" ## \".join(hits)\n",
    "DF_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_features.insert(0, \"CSI_predictions_name\", \"\")\n",
    "DF_features.insert(0, \"CSI_predictions_formula\", \"\")\n",
    "DF_features.insert(0, \"CSI_predictions_smiles\", \"\")\n",
    "\n",
    "for i, id, sirius in zip(DF_features.index, DF_features[\"feature_ids\"], DF_features[\"SIRIUS_predictions\"]):\n",
    "    hits1 = []\n",
    "    hits2= []\n",
    "    hits3=[]\n",
    "    for name, formula, smiles, Pred_id in zip(DF_CSI[\"name\"], DF_CSI[\"formulas\"], DF_CSI[\"smiles\"], DF_CSI[\"featureId\"]): \n",
    "        if (Pred_id in id) & (formula in sirius):\n",
    "                hit1 = f\"{name}\"\n",
    "                hit2 = f\"{formula}\"\n",
    "                hit3= f\"{smiles}\"\n",
    "                if hit1 not in hits1:\n",
    "                    hits1.append(hit1)\n",
    "                    hits2.append(hit2)\n",
    "                    hits3.append(hit3)\n",
    "    DF_features[\"CSI_predictions_name\"][i] = \" ## \".join(hits1)\n",
    "    DF_features[\"CSI_predictions_formula\"][i] = \" ## \".join(hits2)\n",
    "    DF_features[\"CSI_predictions_smiles\"][i] = \" ## \".join(hits3)\n",
    "DF_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_features.to_csv(os.path.join(\"results\", \"annotations\", \"SiriusCSI_annotated_FeatureMatrix.tsv\"), sep=\"\\t\", index= None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `2) Spectral matching`\n",
    "\n",
    "This step matches spectra with an MGF library and annotates the feature matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_features= pd.read_csv(os.path.join(\"results\", \"annotations\", \"SiriusCSI_annotated_FeatureMatrix.tsv\"), sep=\"\\t\") #here we import the already annotated with sirius and csi predictions feature matrix\n",
    "DF_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MGF file to an MSExperiment format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgf_file= os.path.join(\"results\", \"GNPSexport\", \"MSMS.mgf\")\n",
    "exp = MSExperiment()\n",
    "MascotGenericFile().load(mgf_file, exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform spectral matching with a library in MGF format that is located under \"resources\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database= os.path.join(\"resources\", \"GNPS-LIBRARY.mgf\")\n",
    "speclib = MSExperiment()\n",
    "MascotGenericFile().load(database, speclib)\n",
    "mztab= MzTab()\n",
    "output_mztab= os.path.join(\"results\", \"interim\", \"annotations\", \"MSMS.mzTab\")\n",
    "out_merged= \"\"\n",
    "MSMS_match= MetaboliteSpectralMatching()\n",
    "MSMS_match_par = MSMS_match.getDefaults()\n",
    "MSMS_match_par.setValue('merge_spectra', 'false')\n",
    "MSMS_match.setParameters(MSMS_match_par)\n",
    "MSMS_match.run(exp, speclib, mztab,  String(out_merged))\n",
    "MzTabFile().store(output_mztab, mztab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the mzTab to a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectralmatch=  pyteomics.mztab.MzTab(output_mztab, encoding=\"UTF8\", table_format=\"df\")\n",
    "spectralmatch.metadata\n",
    "df= spectralmatch.small_molecule_table\n",
    "spectralmatch_DF= df.drop(columns= [\"identifier\", \"inchi_key\", \"modifications\", \"calc_mass_to_charge\", \"opt_adduct_ion\", \"taxid\", \"species\", \"database\", \"spectra_ref\", \"search_engine\", \"opt_sec_id\",\"smallmolecule_abundance_std_error_study_variable[1]\", \"smallmolecule_abundance_stdev_study_variable[1]\", \"smallmolecule_abundance_study_variable[1]\", \"chemical_formula\"])\n",
    "spectralmatch_DF=spectralmatch_DF[spectralmatch_DF[\"opt_ppm_error\"] <= 10] \n",
    "spectralmatch_DF=spectralmatch_DF[spectralmatch_DF[\"opt_ppm_error\"] >= -10]\n",
    "spectralmatch_DF=spectralmatch_DF[spectralmatch_DF[\"opt_match_score\"] >= 60]\n",
    "spectralmatch_DF[\"opt_spec_native_id\"]= spectralmatch_DF[\"opt_spec_native_id\"].str.replace(r\"index=\", \"\")\n",
    "spectralmatch_DF       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotate the feature matrix with the spectral matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= os.path.join(\"results\", \"GNPSexport\", \"MSMS.mgf\")\n",
    "file= mgf.MGF(source=path, use_header=True, convert_arrays=2, read_charges=True, read_ions=False, dtype=None, encoding=None)\n",
    "parameters=[]\n",
    "for spectrum in file:\n",
    "    parameters.append(spectrum['params'])\n",
    "mgf_file= pd.DataFrame(parameters)\n",
    "mgf_file[\"feature_id\"]= mgf_file[\"feature_id\"].str.replace(r\"e_\", \"\")\n",
    "\n",
    "df= exp.get_df() #mzML loaded in MSExperiment()\n",
    "for spec in exp:\n",
    "    df[\"index\"]= [spec.getNativeID() for spec in exp]\n",
    "    df[\"SCANS\"]= [spec.getMetaValue(\"Scan_ID\") for spec in exp]\n",
    "df[\"index\"]= df[\"index\"].str.replace(r\"index=\", \"\")\n",
    "\n",
    "spectralmatch_DF.insert(0, \"SCANS\", \"\")\n",
    "\n",
    "for i, idx in zip(spectralmatch_DF.index, spectralmatch_DF[\"opt_spec_native_id\"]):\n",
    "    hits = []\n",
    "    for index, scan_number, in zip(df[\"index\"], df[\"SCANS\"]):\n",
    "        if idx==index:\n",
    "            hit = f\"{scan_number}\"\n",
    "            if hit not in hits:\n",
    "                hits.append(hit)\n",
    "    spectralmatch_DF[\"SCANS\"][i] = \" ## \".join(hits)\n",
    "\n",
    "DF_features[\"id\"]= DF_features[\"id\"].astype(str)\n",
    "DF_features[\"feature_ids\"]= DF_features[\"feature_ids\"].values.tolist()\n",
    "DF_features.insert(0, \"SCANS\", \"\")\n",
    "for i, id in zip(DF_features.index, DF_features[\"id\"]):\n",
    "    hits = []\n",
    "    for scan, feature_id in zip(mgf_file[\"scans\"], mgf_file[\"feature_id\"]): \n",
    "        if feature_id==id:\n",
    "            hit = f\"{scan}\"\n",
    "            if hit not in hits:\n",
    "                hits.append(hit)\n",
    "    DF_features[\"SCANS\"][i] = \" ## \".join(hits)\n",
    "\n",
    "DF_features.insert(0, \"SpectralMatch\", \"\")\n",
    "DF_features.insert(0, \"SpectralMatch_smiles\", \"\")\n",
    "\n",
    "for i, scan in zip(DF_features.index, DF_features[\"SCANS\"]):\n",
    "    hits1 = []\n",
    "    hits2=[]\n",
    "    for name, smiles, scan_number, in zip(spectralmatch_DF[\"description\"],spectralmatch_DF[\"smiles\"], spectralmatch_DF[\"SCANS\"]):\n",
    "        if scan==scan_number:\n",
    "            hit1 = f\"{name}\"\n",
    "            hit2 = f\"{smiles}\"\n",
    "            if hit1 not in hits1:\n",
    "                hits1.append(hit1)\n",
    "                hits2.append(hit2)\n",
    "    DF_features[\"SpectralMatch\"][i] = \" ## \".join(hits1)\n",
    "    DF_features[\"SpectralMatch_smiles\"][i] = \" ## \".join(hits2)\n",
    "DF_features.to_csv(os.path.join(\"results\", \"annotations\", \"SiriusCSI_MSMS_annotated_FeatureMatrix.tsv\"), sep=\"\\t\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d92193107b2c1fde5349325fa7e4180df63966062ebb6172612daf2925f9acf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
