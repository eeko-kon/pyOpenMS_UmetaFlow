{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= os.path.join(\"results\", \"interim\", \"analysis\")\n",
    "isExist= os.path.exists(path)\n",
    "if not isExist:\n",
    "    os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First,import the feature table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureMatrix= os.path.join(\"results\", \"features\", \"FeatureMatrix.tsv\")\n",
    "DF_features= pd.read_csv(FeatureMatrix, sep=\"\\t\")\n",
    "DF_features=DF_features.set_index([\"mz\", \"RT\"])\n",
    "DF_features= DF_features.drop(columns=[\"charge\", \"quality\", \"id\"])\n",
    "DF_features= DF_features.fillna(0)\n",
    "DF_features[\"feature_ids\"]= [ids[1:-1].split(\",\") for ids in DF_features[\"feature_ids\"]]\n",
    "DF_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_features= DF_features.reset_index()\n",
    "DF_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `1) GNPS annotations`\n",
    "\n",
    "This step requires an independent job at GNPS Spectral Library Search (input: raw mzML files)\n",
    "See documentation: https://ccms-ucsd.github.io/GNPSDocumentation/librarysearch/ \n",
    "\n",
    "When the job is finished, import all identifications from GNPS, save the .TSV table under the resources directory and \"clean up\" the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(os.path.join(\"resources\", \"MS2_LIBRARYSEARCH_all_identifications.tsv\"), sep=\"\\t\", encoding=\"latin-1\")\n",
    "df.drop(df.index[df[\"IonMode\"] == \"negative\"], inplace=True)\n",
    "df.drop(df.index[df[\"MZErrorPPM\"] > 20.0], inplace=True)\n",
    "GNPS=df.filter([\"Compound_Name\", \"RT_Query\", \"Precursor_MZ\"])\n",
    "GNPS=GNPS.rename(columns= {\"RT_Query\": \"RetentionTime\"})\n",
    "GNPS=GNPS.drop_duplicates(subset=\"Compound_Name\", keep=\"first\")\n",
    "GNPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotate the features detected by GNPS according to mz and RT (mz tolerance 10 ppm and RT tolerance 20 seconds: instrument and method-dependent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= os.path.join(\"results\", \"annotations\")\n",
    "isExist= os.path.exists(path)\n",
    "if not isExist:\n",
    "    os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_features.insert(0, \"GNPS_IDs\", \"\")\n",
    "\n",
    "for i, mz, rt in zip(DF_features.index, DF_features[\"mz\"], DF_features[\"RT\"]):\n",
    "    hits = []\n",
    "    for name, GNPS_mz, GNPS_rt, in zip(GNPS[\"Compound_Name\"], GNPS[\"Precursor_MZ\"], GNPS[\"RetentionTime\"]):\n",
    "        mass_delta = (abs(GNPS_mz-mz)/GNPS_mz)*1000000.0 if GNPS_mz != 0 else np.nan\n",
    "        if (GNPS_rt >= rt-20.0) & (GNPS_rt <= rt+20.0) & (mass_delta<= 10.0):\n",
    "            hit = f\"{name}\"\n",
    "            if hit not in hits:\n",
    "                hits.append(hit)\n",
    "    DF_features[\"GNPS_IDs\"][i] = \" ## \".join(hits)\n",
    "\n",
    "DF_features.to_csv(os.path.join(path, \"GNPS_annotated_feature_matrix.tsv\"), sep=\"\\t\", index = False)\n",
    "DF_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep the unannotated features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureMatrix= DF_features[DF_features.GNPS_IDs == \"\"]\n",
    "FeatureMatrix= FeatureMatrix.drop(columns= \"GNPS_IDs\")\n",
    "FeatureMatrix= FeatureMatrix.set_index([\"RT\", \"mz\"])\n",
    "FeatureMatrix_tocsv= FeatureMatrix.reset_index()\n",
    "FeatureMatrix_tocsv.to_csv(os.path.join(\"results\", \"annotations\", \"FeatureMatrix_unknowns.tsv\"), sep=\"\\t\", index =None)\n",
    "FeatureMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `2) SIRIUS and CSI:FingerID annotations`\n",
    "\n",
    "Create a matrix with all SIRIUS and CSI:FingerID formula and structural predictions, only choose #1 rankings predictions and combine the dataframes to annotate formula and structural predictions according to RT and mz:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_formulas will likely contain duplicate formulas that could be either isomeric, isobaric compounds, or identical compounds (with identical RT and mz). Here, we want to collapse the identical, repeating compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_formulas= glob.glob(os.path.join(\"results\", \"Sirius\", \"formulas_*.tsv\"))\n",
    "DF_SIRIUS = pd.DataFrame()\n",
    "list_of_df=[]\n",
    "for csv in input_formulas:\n",
    "    df= pd.read_csv(csv, sep=\"\\t\", index_col=\"Unnamed: 0\")\n",
    "    s= df[\"opt_global_rank\"]\n",
    "    pd.to_numeric(s)\n",
    "    df= df.loc[df[\"opt_global_rank\"]==1]\n",
    "    df= df.rename(columns={\"opt_global_featureId\":\"featureId\"})\n",
    "    df= df.drop(columns=df.filter(regex=fr\"Score\").columns)\n",
    "    df= df.drop(columns= df.filter(regex=fr\"opt\").columns)\n",
    "    df=df.reset_index()\n",
    "    list_of_df.append(df)\n",
    "DF_SIRIUS= pd.concat(list_of_df,ignore_index=True)\n",
    "DF_SIRIUS= DF_SIRIUS.drop(columns=\"index\")\n",
    "DF_SIRIUS= DF_SIRIUS.rename(columns= {\"chemical_formula\": \"formulas\", \"exp_mass_to_charge\": \"mz\", \"retention_time\": \"RT\"})\n",
    "DF_SIRIUS[\"featureId\"]= DF_SIRIUS[\"featureId\"].str.replace(r\"id_\", \"\")\n",
    "for i, rows in DF_SIRIUS.iterrows():\n",
    "    DF_SIRIUS[\"featureId\"][i]= DF_SIRIUS[\"featureId\"][i].split(\",\")\n",
    "DF_SIRIUS.to_csv(os.path.join(\"results\", \"annotations\", \"SIRIUS_library.tsv\"), sep=\"\\t\", index=None)\n",
    "DF_SIRIUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for structral predictions (remove duplicates with the same inchi_keys, which means they represent the same structure):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_structures= glob.glob(os.path.join(\"results\", \"Sirius\", \"structures_*.tsv\"))\n",
    "DF_CSI = pd.DataFrame()\n",
    "list_of_df=[]\n",
    "for csv in input_structures:\n",
    "    df= pd.read_csv(csv, sep=\"\\t\", index_col=\"Unnamed: 0\")\n",
    "    s= df[\"opt_global_rank\"]\n",
    "    pd.to_numeric(s)\n",
    "    df= df.loc[df[\"opt_global_rank\"]==1]\n",
    "    df= df.rename(columns={\"opt_global_featureId\":\"featureId\"})\n",
    "    df= df.drop(columns=df.filter(regex=fr\"Score\").columns)\n",
    "    df= df.drop(columns= df.filter(regex=fr\"opt\").columns)\n",
    "    df=df.reset_index()\n",
    "    list_of_df.append(df)\n",
    "DF_CSI= pd.concat(list_of_df,ignore_index=True)\n",
    "DF_CSI= DF_CSI.drop(columns=\"index\")\n",
    "DF_CSI= DF_CSI.rename(columns= {\"chemical_formula\": \"formulas\", \"exp_mass_to_charge\": \"mz\", \"retention_time\": \"RT\", \"description\":\"name\"})\n",
    "DF_CSI[\"featureId\"]= DF_CSI[\"featureId\"].str.replace(r\"id_\", \"\")\n",
    "for i, rows in DF_CSI.iterrows():\n",
    "    DF_CSI[\"featureId\"][i]= DF_CSI[\"featureId\"][i].split(\",\")\n",
    "DF_CSI.to_csv(os.path.join(\"results\", \"annotations\", \"CSI_library.tsv\"), sep=\"\\t\", index=None)\n",
    "DF_CSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotate the formulas and structural predictions to the feature matrix according to SIRIUS and CSI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_features.insert(0, \"SIRIUS_predictions\", \"\")\n",
    "\n",
    "for i, id in zip(DF_features.index, DF_features[\"feature_ids\"]):\n",
    "    hits = []\n",
    "    for name, Pred_id in zip(DF_SIRIUS[\"formulas\"], DF_SIRIUS[\"featureId\"]): \n",
    "        for x,y in zip(id,Pred_id):\n",
    "            if x==y:\n",
    "                hit = f\"{name}\"\n",
    "                if hit not in hits:\n",
    "                    hits.append(hit)\n",
    "    DF_features[\"SIRIUS_predictions\"][i] = \" ## \".join(hits)\n",
    "DF_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_features.insert(0, \"CSI_predictions_name\", \"\")\n",
    "DF_features.insert(0, \"CSI_predictions_formula\", \"\")\n",
    "DF_features.insert(0, \"CSI_predictions_smiles\", \"\")\n",
    "\n",
    "for i, id, sirius in zip(DF_features.index, DF_features[\"feature_ids\"], DF_features[\"SIRIUS_predictions\"]):\n",
    "    hits1 = []\n",
    "    hits2= []\n",
    "    hits3=[]\n",
    "    for name, formula, smiles, Pred_id in zip(DF_CSI[\"name\"], DF_CSI[\"formulas\"], DF_CSI[\"smiles\"], DF_CSI[\"featureId\"]): \n",
    "        for x,y in zip(id,Pred_id):\n",
    "            if (x==y)& (formula in sirius):\n",
    "                hit1 = f\"{name}\"\n",
    "                hit2 = f\"{formula}\"\n",
    "                hit3= f\"{smiles}\"\n",
    "                if hit1 not in hits1:\n",
    "                    hits1.append(hit1)\n",
    "                    hits2.append(hit2)\n",
    "                    hits3.append(hit3)\n",
    "    DF_features[\"CSI_predictions_name\"][i] = \" ## \".join(hits1)\n",
    "    DF_features[\"CSI_predictions_formula\"][i] = \" ## \".join(hits2)\n",
    "    DF_features[\"CSI_predictions_smiles\"][i] = \" ## \".join(hits3)\n",
    "DF_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_features.to_csv(os.path.join(\"results\", \"annotations\", \"FeatureMatrix_SIRIUS_CSI.csv\"), sep=\"\\t\", index= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edde62aa2661007f0756e9790e7a328c288a583bf6ce768a355147dac67c8db8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pyopenms')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
