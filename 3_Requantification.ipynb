{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Determination of memory status is not supported on this \n",
      " platform, measuring for memoryleaks will never fail\n"
     ]
    }
   ],
   "source": [
    "from pyopenms import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Re-quantification workflow`\n",
    "\n",
    "This workflow consists of 3 steps. The purpose is missing value imputation caused by the preprocessing algorithms.\n",
    "\n",
    "#### `1) Create a library (MetaboliteIdentification table)` \n",
    "\n",
    "The first step is to create a library of compounds derived from the features generated from all files in the pre-processing steps. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CompoundName</th>\n",
       "      <th>SumFormula</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Charge</th>\n",
       "      <th>RetentionTime</th>\n",
       "      <th>RetentionTimeRange</th>\n",
       "      <th>IsoDistribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feature_0</td>\n",
       "      <td></td>\n",
       "      <td>227.162753</td>\n",
       "      <td>+1</td>\n",
       "      <td>91.263603</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feature_1</td>\n",
       "      <td></td>\n",
       "      <td>154.073687</td>\n",
       "      <td>+1</td>\n",
       "      <td>85.650543</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feature_2</td>\n",
       "      <td></td>\n",
       "      <td>431.230151</td>\n",
       "      <td>+1</td>\n",
       "      <td>526.956299</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feature_3</td>\n",
       "      <td></td>\n",
       "      <td>421.241870</td>\n",
       "      <td>+1</td>\n",
       "      <td>71.314590</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feature_4</td>\n",
       "      <td></td>\n",
       "      <td>227.187930</td>\n",
       "      <td>+1</td>\n",
       "      <td>474.451019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17941</th>\n",
       "      <td>feature_17941</td>\n",
       "      <td></td>\n",
       "      <td>1060.566137</td>\n",
       "      <td>+2</td>\n",
       "      <td>306.633545</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17942</th>\n",
       "      <td>feature_17942</td>\n",
       "      <td></td>\n",
       "      <td>402.221655</td>\n",
       "      <td>+2</td>\n",
       "      <td>61.321491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17943</th>\n",
       "      <td>feature_17943</td>\n",
       "      <td></td>\n",
       "      <td>1173.504736</td>\n",
       "      <td>+2</td>\n",
       "      <td>274.222290</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17944</th>\n",
       "      <td>feature_17944</td>\n",
       "      <td></td>\n",
       "      <td>2026.940893</td>\n",
       "      <td>+2</td>\n",
       "      <td>310.961517</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17945</th>\n",
       "      <td>feature_17945</td>\n",
       "      <td></td>\n",
       "      <td>711.344592</td>\n",
       "      <td>+1</td>\n",
       "      <td>356.341675</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17946 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CompoundName SumFormula         Mass Charge  RetentionTime  \\\n",
       "0          feature_0              227.162753     +1      91.263603   \n",
       "1          feature_1              154.073687     +1      85.650543   \n",
       "2          feature_2              431.230151     +1     526.956299   \n",
       "3          feature_3              421.241870     +1      71.314590   \n",
       "4          feature_4              227.187930     +1     474.451019   \n",
       "...              ...        ...          ...    ...            ...   \n",
       "17941  feature_17941             1060.566137     +2     306.633545   \n",
       "17942  feature_17942              402.221655     +2      61.321491   \n",
       "17943  feature_17943             1173.504736     +2     274.222290   \n",
       "17944  feature_17944             2026.940893     +2     310.961517   \n",
       "17945  feature_17945              711.344592     +1     356.341675   \n",
       "\n",
       "      RetentionTimeRange IsoDistribution  \n",
       "0                      0               0  \n",
       "1                      0               0  \n",
       "2                      0               0  \n",
       "3                      0               0  \n",
       "4                      0               0  \n",
       "...                  ...             ...  \n",
       "17941                  0               0  \n",
       "17942                  0               0  \n",
       "17943                  0               0  \n",
       "17944                  0               0  \n",
       "17945                  0               0  \n",
       "\n",
       "[17946 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the consensus tsv table and keep only the columns: RT, mz and charge\n",
    "DF_features = pd.read_csv(\"results/GNPSexport/interim/consensus.tsv\", sep=\"\\t\")\n",
    "DF_features = DF_features[['RT','mz', \"charge\"]]\n",
    "\n",
    "#convert the mz and RT columns to floats and charge to integer for calculations\n",
    "DF_features[\"charge\"] = pd.to_numeric(DF_features[\"charge\"], downcast=\"integer\")\n",
    "DF_features[\"mz\"] = pd.to_numeric(DF_features[\"mz\"], downcast=\"float\")\n",
    "DF_features[\"RT\"] = pd.to_numeric(DF_features[\"RT\"], downcast=\"float\")\n",
    "\n",
    "#Add a columns named \"Mass\" and calculate the neutral masses from the charge and mz:\n",
    "DF_features[\"Mass\"]= 0.0\n",
    "for ind in DF_features.index:\n",
    "    if DF_features[\"charge\"][ind] == 0:\n",
    "        DF_features.loc[ind, \"Mass\"]= DF_features.loc[ind,\"mz\"]\n",
    "    if DF_features[\"charge\"][ind] == 1:\n",
    "        DF_features.loc[ind, \"Mass\"]= DF_features.loc[ind,\"mz\"]- 1.007825\n",
    "    if DF_features[\"charge\"][ind] == 2:\n",
    "        DF_features.loc[ind, \"Mass\"]= (DF_features.loc[ind,\"mz\"]*2)- 2.015650\n",
    "    if DF_features[\"charge\"][ind] == 3:\n",
    "        DF_features.loc[ind, \"Mass\"]= (DF_features.loc[ind,\"mz\"]*3)- 3.023475\n",
    "\n",
    "#Rename columns to the required ones and add positive or negative sign for charge\n",
    "DF_features= DF_features.rename(columns={\"RT\": \"RetentionTime\", \"charge\":\"Charge\"})\n",
    "DF_features[\"Charge\"]= DF_features[\"Charge\"].astype(str)\n",
    "for ind in DF_features.index:\n",
    "    if DF_features[\"Charge\"][ind] == \"1\":\n",
    "        DF_features.loc[ind, \"Charge\"]= \"+\" + DF_features.loc[ind,\"Charge\"]\n",
    "    if DF_features[\"Charge\"][ind] == \"2\":\n",
    "        DF_features.loc[ind, \"Charge\"]= \"+\" + DF_features.loc[ind,\"Charge\"]\n",
    "    if DF_features[\"Charge\"][ind] == \"3\":\n",
    "        DF_features.loc[ind, \"Charge\"]= \"+\" + DF_features.loc[ind,\"Charge\"]\n",
    "#drop the mz column\n",
    "DF_features= DF_features.drop(columns= \"mz\")\n",
    "\n",
    "#add the rest of the columns required for the MetaboliteIdentificationTable and fill with zeros or blanks, except the \"Compound Name\"\n",
    "#which, since they are all unknown, can be filled with feature_#\n",
    "DF_features['CompoundName'] = np.arange(len(DF_features))\n",
    "DF_features['CompoundName'] = \"feature_\" + DF_features['CompoundName'].astype(str)\n",
    "DF_features[\"SumFormula\"] = \" \"\n",
    "DF_features[\"RetentionTimeRange\"]= \"0\"\n",
    "DF_features[\"IsoDistribution\"]= \"0\"\n",
    "DF_features= DF_features[[\"CompoundName\",\"SumFormula\", \"Mass\",\"Charge\",\"RetentionTime\",\"RetentionTimeRange\", \"IsoDistribution\"]]\n",
    "DF_features.to_csv(\"resources/MetaboliteIdentification.tsv\", sep=\"\\t\", index= None)\n",
    "DF_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `2) MapAlignmentTransformer`\n",
    "This algorithm is used to perform a linear retention time alignment, in order to correct for chromatographic shifts in retention time. Use the trafo XML files from the feature alignment and align the raw spectra.\n",
    "\n",
    "###### Documentation: https://abibuilder.informatik.uni-tuebingen.de/archive/openms/Documentation/nightly/html/classOpenMS_1_1MapAlignmentTransformer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_mzml_files = sorted(glob.glob('results/interim/PCpeak_*.mzML'))\n",
    "input_trafo = sorted(glob.glob('results/GNPSexport/interim/*.trafoXML'))\n",
    "\n",
    "for filename in input_mzml_files:\n",
    "    exp= MSExperiment()\n",
    "    MzMLFile().load(filename, exp)\n",
    "    exp.sortSpectra(True)\n",
    "    transformer = MapAlignmentTransformer()\n",
    "\n",
    "    for trafo_XML in input_trafo:\n",
    "        trafo=TransformationDescription()\n",
    "        TransformationXMLFile().load(trafo_XML, trafo, True)\n",
    "        if os.path.basename(trafo_XML)[11:-9] == os.path.basename(filename)[7:-5]:\n",
    "            transformer.transformRetentionTimes(exp, trafo, True)\n",
    "            mzml_file = os.path.join(\"results\", \"\", \"Requant\", \"\", \"interim\", \"\", 'MapAligned_' + os.path.basename(exp.getLoadedFilePath())[7:-5] +\".mzML\")\n",
    "            MzMLFile().store(mzml_file, exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `2) FeatureFinderMetaboIdent`\n",
    "This algorithm detects and extracts MS1 data that match the feature list in the metabolite identification table.\n",
    "\n",
    "###### Documentation: https://abibuilder.informatik.uni-tuebingen.de/archive/openms/Documentation/nightly/html/UTILS_FeatureFinderMetaboIdent.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# read tsv file and create list of FeatureFinderMetaboIdentCompound\n",
    "def metaboTableFromFile(path_to_library_file):\n",
    "    metaboTable = []\n",
    "    with open(path_to_library_file, 'r') as tsv_file:\n",
    "        tsv_reader = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "        next(tsv_reader) # skip header\n",
    "        for row in tsv_reader:\n",
    "            metaboTable.append(FeatureFinderMetaboIdentCompound(\n",
    "                row[0], # name\n",
    "                row[1], # sum formula\n",
    "                float(row[2]), # mass\n",
    "                [int(charge) for charge in row[3].split(',')], # charges\n",
    "                [float(rt) for rt in row[4].split(',')], # RTs\n",
    "                [float(rt_range) for rt_range in row[5].split(',')], # RT ranges\n",
    "                [float(iso_distrib) for iso_distrib in row[6].split(',')] # isotope distributions\n",
    "            ))\n",
    "    return metaboTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_mzml_files=sorted(glob.glob(\"results/Requant/interim/*.mzML\"))\n",
    "# load ms data from mzML file into MSExperiment\n",
    "for mzml_file in input_mzml_files:\n",
    "    spectra = MSExperiment()\n",
    "    MzMLFile().load(mzml_file, spectra)\n",
    "\n",
    "    # create FeatureFinderAlgorithmMetaboIdent and assign ms data\n",
    "    ff = FeatureFinderAlgorithmMetaboIdent()\n",
    "    ff.setMSData(spectra)\n",
    "\n",
    "    # read library generate a metabo table with compounds\n",
    "    metabo_table = metaboTableFromFile('resources/MetaboliteIdentification.tsv')\n",
    "\n",
    "    params = ff.getParameters()\n",
    "    params[b'extract:mz_window'] = 5.0 \n",
    "    params[b'detect:peak_width'] = 20.0  #adjust for wide peaks\n",
    "    ff.setParameters(params)\n",
    "    # FeatureMap to store results\n",
    "    fm = FeatureMap()\n",
    "    # run the FeatureFinderMetaboIdent with the metabo_table and store results in fm\n",
    "    ff.run(metabo_table, fm) #, String(mzml_file)\n",
    "\n",
    "    # save FeatureMap to file\n",
    "    ff_file = os.path.join(\"results\", \"\", \"Requant\", \"\", \"interim\", \"\", 'FFMI_' + os.path.basename(mzml_file)[11:-5] +\".featureXML\")\n",
    "    FeatureXMLFile().store(ff_file, fm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the features as a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_feature_files = sorted(glob.glob('results/Requant/interim/FFMI_*.featureXML'))\n",
    "\n",
    "for filename in input_feature_files:\n",
    "    fmap = FeatureMap()\n",
    "    FeatureXMLFile().load(filename, fmap)\n",
    "    DF= fmap.get_df()\n",
    "    feature_csv= os.path.join(\"results\", \"\", \"Requant\", \"\", 'features_' +  os.path.basename(fmap.getMetaValue('spectra_data')[0].decode())[11:-5] +\".csv\")\n",
    "    DF.to_csv(feature_csv)\n",
    "    print(os.path.basename(filename))\n",
    "    display(DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `3) FeatureGroupingAlgorithmKD `\n",
    "\n",
    "Feature linker aggregates the feature information (from single files) into a ConsensusFeature, linking features from different files together, which have a smiliar m/z and rt (no MS2 data).\n",
    "\n",
    "###### Documentation: https://abibuilder.informatik.uni-tuebingen.de/archive/openms/Documentation/release/latest/html/TOPP_FeatureLinkerUnlabeledKD.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['results/Requant/interim/FFMI_20210827_UMETAB219_POS_DNPM_Plate-2_MDNAWGS14_blank.featureXML', 'results/Requant/interim/FFMI_20210827_UMETAB219_POS_DNPM_Plate-2_MDNAWGS14_rep1.featureXML', 'results/Requant/interim/FFMI_20210827_UMETAB219_POS_DNPM_Plate-2_MDNAWGS14_rep2.featureXML', 'results/Requant/interim/FFMI_20210827_UMETAB219_POS_DNPM_Plate-2_MDNAWGS14_rep3.featureXML', 'results/Requant/interim/FFMI_20210827_UMETAB219_POS_FPY12_Plate-2_MDNAWGS14_blank.featureXML', 'results/Requant/interim/FFMI_20210827_UMETAB219_POS_FPY12_Plate-2_MDNAWGS14_rep1.featureXML', 'results/Requant/interim/FFMI_20210827_UMETAB219_POS_FPY12_Plate-2_MDNAWGS14_rep2.featureXML', 'results/Requant/interim/FFMI_20210827_UMETAB219_POS_FPY12_Plate-2_MDNAWGS14_rep3.featureXML', 'results/Requant/interim/FFMI_20210827_UMETAB219_POS_ISP2_Plate-2_MDNAWGS14_blank.featureXML', 'results/Requant/interim/FFMI_20210827_UMETAB219_POS_ISP2_Plate-2_MDNAWGS14_rep1.featureXML', 'results/Requant/interim/FFMI_20210827_UMETAB219_POS_ISP2_Plate-2_MDNAWGS14_rep2.featureXML', 'results/Requant/interim/FFMI_20210827_UMETAB219_POS_ISP2_Plate-2_MDNAWGS14_rep3.featureXML']\n",
      "Progress of 'computing RT transformations':\n",
      "-- done [took 0.54 s (CPU), 0.55 s (Wall)] -- \n",
      "Progress of 'linking features':\n",
      "-- done [took 0.89 s (CPU), 0.89 s (Wall)] -- \n",
      "ConsensusXMLFile::store():  found 9124 invalid unique ids\n"
     ]
    }
   ],
   "source": [
    "feature_grouper = FeatureGroupingAlgorithmKD()\n",
    "\n",
    "consensus_map = ConsensusMap()\n",
    "file_descriptions = consensus_map.getColumnHeaders()\n",
    "\n",
    "input_feature_files = sorted(glob.glob('results/Requant/interim/*.featureXML'))\n",
    "\n",
    "feature_maps = []\n",
    "for featurexml_file in input_feature_files:\n",
    "    fmap = FeatureMap()\n",
    "    FeatureXMLFile().load(featurexml_file, fmap)\n",
    "    feature_maps.append(fmap)\n",
    "\n",
    "for i, feature_map in enumerate(feature_maps):\n",
    "    file_description = file_descriptions.get(i, ColumnHeader())\n",
    "    file_description.filename = os.path.basename(feature_map.getMetaValue('spectra_data')[0].decode())[34:-5]\n",
    "    file_description.size = feature_map.size()\n",
    "    file_descriptions[i] = file_description\n",
    "\n",
    "feature_grouper.group(feature_maps, consensus_map)\n",
    "consensus_map.setColumnHeaders(file_descriptions)\n",
    "\n",
    "Consensus_file= os.path.join(\"results\", \"\", \"Requant\", \"\",\"interim\", \"\", 'consensus' + \".consensusXML\")\n",
    "ConsensusXMLFile().store(Consensus_file, consensus_map)\n",
    "\n",
    "# get intensities as a DataFrame\n",
    "result = consensus_map.get_df()\n",
    "result= result.reset_index()\n",
    "result= result.drop(columns= [\"id\", \"sequence\", \"quality\"])\n",
    "# store as tsv file\n",
    "result.to_csv('results/Requant/FeatureMatrix.tsv', sep = '\\t', index = False)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the preprocessed and requantified numbers of features (missing values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_20210827_UMETAB219_POS_ISP2_Plate-2_MDNAWGS14_blank.csv\n",
      "Preprocessed: 1267 Requantified: 5294\n",
      "features_20210827_UMETAB219_POS_DNPM_Plate-2_MDNAWGS14_rep1.csv\n",
      "Preprocessed: 623 Requantified: 4467\n",
      "features_20210827_UMETAB219_POS_DNPM_Plate-2_MDNAWGS14_rep3.csv\n",
      "Preprocessed: 556 Requantified: 4451\n",
      "features_20210827_UMETAB219_POS_DNPM_Plate-2_MDNAWGS14_rep2.csv\n",
      "Preprocessed: 543 Requantified: 4923\n",
      "features_20210827_UMETAB219_POS_ISP2_Plate-2_MDNAWGS14_rep2.csv\n",
      "Preprocessed: 523 Requantified: 4068\n",
      "features_20210827_UMETAB219_POS_FPY12_Plate-2_MDNAWGS14_blank.csv\n",
      "Preprocessed: 3008 Requantified: 5045\n",
      "features_20210827_UMETAB219_POS_ISP2_Plate-2_MDNAWGS14_rep3.csv\n",
      "Preprocessed: 532 Requantified: 3807\n",
      "features_20210827_UMETAB219_POS_ISP2_Plate-2_MDNAWGS14_rep1.csv\n",
      "Preprocessed: 636 Requantified: 3936\n",
      "features_20210827_UMETAB219_POS_FPY12_Plate-2_MDNAWGS14_rep3.csv\n",
      "Preprocessed: 2436 Requantified: 6625\n",
      "features_20210827_UMETAB219_POS_FPY12_Plate-2_MDNAWGS14_rep2.csv\n",
      "Preprocessed: 2350 Requantified: 6701\n",
      "features_20210827_UMETAB219_POS_DNPM_Plate-2_MDNAWGS14_blank.csv\n",
      "Preprocessed: 2112 Requantified: 4990\n",
      "features_20210827_UMETAB219_POS_FPY12_Plate-2_MDNAWGS14_rep1.csv\n",
      "Preprocessed: 2144 Requantified: 6597\n"
     ]
    }
   ],
   "source": [
    "from pyopenms import *\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "Preprocessed= glob.glob(\"results/features/*.csv\")\n",
    "Requantified= glob.glob(\"results/Requant/*.csv\")\n",
    "\n",
    "for table in Preprocessed:\n",
    "    df1= pd.read_csv(table)\n",
    "    feature_no= len(df1)\n",
    "\n",
    "    for matrix in Requantified:\n",
    "        df2= pd.read_csv(matrix)\n",
    "        requant_no= len(df2)\n",
    "\n",
    "        if os.path.basename(table)== os.path.basename(matrix):\n",
    "            print(os.path.basename(matrix))\n",
    "            print(\"Preprocessed:\", feature_no, \"Requantified:\", requant_no)\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edde62aa2661007f0756e9790e7a328c288a583bf6ce768a355147dac67c8db8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
