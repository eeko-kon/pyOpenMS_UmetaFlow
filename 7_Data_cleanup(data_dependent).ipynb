{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureMatrix= os.path.join(\"results\", \"features\", \"FeatureMatrix.tsv\")\n",
    "DF_features= pd.read_csv(FeatureMatrix, sep=\"\\t\")\n",
    "DF_features=DF_features.set_index([\"mz\", \"RT\"])\n",
    "DF_features= DF_features.drop(columns=[\"charge\", \"quality\", \"id\"])\n",
    "DF_features= DF_features.fillna(0)\n",
    "DF_features[\"feature_ids\"]= [ids[1:-1].split(\",\") for ids in DF_features[\"feature_ids\"]]\n",
    "DF_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1) Filter the feature matrix (optional)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= os.path.join(\"results\", \"interim\", \"analysis\")\n",
    "isExist= os.path.exists(path)\n",
    "if not isExist:\n",
    "    os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a (i) Remove all features detected in negative controls (make sure there is no cross-contamination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_list= [r\"ISP2\", r\"FPY12\", r\"DNPM\"] # different media/conditions (treatments)\n",
    "for medium in media_list:\n",
    "    Features_flt=DF_features.filter(regex=fr\"{medium}\")\n",
    "    blanks= Features_flt.filter(regex=\"blank\", axis= 1) \n",
    "    blanks = blanks.fillna(0)\n",
    "    blanks= blanks.transpose()\n",
    "    dictionary = {}\n",
    "    cols= blanks.columns\n",
    "    for i, col in enumerate(cols):\n",
    "        dictionary[i] = np.count_nonzero(blanks[col]) / len(blanks[col])\n",
    "    column_idx = [key for key, value in dictionary.items() if value >= 0.5] #Remove features that appear most frequently (in more than 50% of the samples) in the negative controls\n",
    "    print(dictionary)\n",
    "    blank_features= blanks.iloc[:, column_idx] \n",
    "    cols= blank_features.columns\n",
    "    Features_flt= Features_flt.transpose()\n",
    "    Features_nb= Features_flt.drop(columns= cols)\n",
    "    Features_nb= Features_nb.dropna(how=\"all\")\n",
    "    blanks=blanks.transpose()\n",
    "    blank_cols= blanks.columns\n",
    "    Features_nb= Features_flt.drop(columns=blank_cols)\n",
    "    filename= os.path.join(path, \"No_NC_\"+ medium + \"_DF_features.csv\")\n",
    "    Features_nb.to_csv(filename, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a (ii) Or if there are multiple replicates, remove only the features detected in more than 50% of all the negative controls (or blanks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_list= [r\"ISP2\", r\"FPY12\", r\"DNPM\"] # different media/conditions (treatments)\n",
    "for medium in media_list:\n",
    "    Features_flt=DF_features.filter(regex=fr\"{medium}\")\n",
    "    blanks= Features_flt.filter(regex=\"blank\", axis= 1) \n",
    "    blanks = blanks.fillna(0)\n",
    "    blanks= blanks.transpose()\n",
    "    cols= blanks.columns\n",
    "    Features_flt= Features_flt.transpose()\n",
    "    Features_nb= Features_flt.drop(columns= cols)\n",
    "    Features_nb= Features_nb.dropna(how=\"all\")\n",
    "    blanks=blanks.transpose()\n",
    "    blank_cols= blanks.columns\n",
    "    Features_flt= Features_flt.transpose()\n",
    "    Features_nb= Features_flt.drop(columns=blank_cols)\n",
    "    filename= os.path.join(path, \"No_NC_\"+ medium + \"_DF_features.csv\")\n",
    "    Features_nb.to_csv(filename, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Replace the features that have lower intensity than 10^4 with NaN (noise for Orbitrap instruments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_flt(csvfile):   \n",
    "    Features= pd.read_csv(csvfile, sep=\"\\t\")\n",
    "    Features= Features.set_index([\"mz\", \"RT\"])\n",
    "    Features= Features.sort_index(axis=1) \n",
    "    cols= Features.columns\n",
    "    Features[cols] = Features[cols].replace({0:np.nan})\n",
    "    Features[Features<10000] = np.nan\n",
    "    Featuresnew=Features.dropna(how=\"all\")\n",
    "    Featuresnew = Featuresnew.fillna(0)\n",
    "    DF= Featuresnew.reset_index()\n",
    "    file_path = os.path.join(os.path.dirname(csvfile), 'noise_thr_' + os.path.basename(csvfile)[6:])\n",
    "    DF.to_csv(file_path, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfiles= glob.glob(os.path.join(path, \"No_NC_*.csv\"))\n",
    "for csvfile in csvfiles:\n",
    "    noise_flt(csvfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Replace the presence of a feature with NaN if the feature is present in only 1 out of 3 replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_filter(csvfile):\n",
    "    Features= pd.read_csv(csvfile, sep=\"\\t\", index_col=\"Unnamed: 0\")\n",
    "    Features= Features.set_index([\"mz\", \"RT\"])\n",
    "    Features= Features.sort_index(axis=1)\n",
    "    cols= Features.columns\n",
    "    Features= Features.fillna(0)\n",
    "    Features= Features.transpose()\n",
    "    Features= Features.reset_index()\n",
    "    Features['genomeID']=Features['index'].str.extract(r'(NBC_?\\d*)')\n",
    "    Features['genomeID_MDNA']=Features['index'].str.extract(r'(MDNAWGS?\\d*|MDNA_WGS_?\\d*)')\n",
    "    Features['genomeID']=Features['genomeID'].fillna(Features['genomeID_MDNA'])\n",
    "    Features= Features.drop(columns=[\"genomeID_MDNA\"])\n",
    "    Features=Features.set_index([\"index\"])\n",
    "    Grouped= Features.groupby(\"genomeID\")\n",
    "    DF= Grouped.transform(lambda x: np.nan if np.count_nonzero(x)<2 else x)\n",
    "    DF=DF.transpose()\n",
    "    DF=DF.reset_index()\n",
    "    file_path = os.path.join(os.path.dirname(csvfile), os.path.basename(csvfile)[10:])\n",
    "    DF.to_csv(file_path, sep=\"\\t\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfiles= glob.glob(os.path.join(path, \"noise_thr_*.csv\"))\n",
    "for csvfile in csvfiles:\n",
    "    rep_filter(csvfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Merge all tables on mz and RT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Matrix_FPY12= pd.read_csv(os.path.join(path, \"FPY12_DF_features.csv\"), sep=\"\\t\")\n",
    "Matrix_ISP2= pd.read_csv(os.path.join(path, \"ISP2_DF_features.csv\"), sep=\"\\t\")\n",
    "Matrix_DNPM= pd.read_csv(os.path.join(path, \"DNPM_DF_features.csv\"), sep=\"\\t\")\n",
    "\n",
    "Matrix_ISP2= Matrix_ISP2.set_index([\"mz\", \"RT\"])\n",
    "Matrix_ISP2= Matrix_ISP2.fillna(0)\n",
    "Matrix_ISP2= Matrix_ISP2.sort_index(axis=1)\n",
    "\n",
    "Matrix_FPY12= Matrix_FPY12.set_index([\"mz\", \"RT\"])\n",
    "Matrix_FPY12= Matrix_FPY12.sort_index(axis=1)\n",
    "Matrix_FPY12= Matrix_FPY12.fillna(0)\n",
    "\n",
    "Matrix_DNPM= Matrix_DNPM.set_index([\"mz\", \"RT\"])\n",
    "Matrix_DNPM= Matrix_DNPM.fillna(0)\n",
    "Matrix_DNPM= Matrix_DNPM.sort_index(axis=1)\n",
    "\n",
    "Matrix_ISP2_FPY12= pd.merge(Matrix_FPY12, Matrix_ISP2, on=[\"mz\", \"RT\"], how=\"outer\")\n",
    "Matrix= pd.merge(Matrix_ISP2_FPY12, Matrix_DNPM, on=[\"mz\", \"RT\"],how= \"outer\")\n",
    "cols= Matrix.columns\n",
    "Matrix[cols] = Matrix[cols].replace({0:np.nan})\n",
    "Matrix= Matrix.dropna(how=\"all\")\n",
    "Matrix= Matrix.reset_index()\n",
    "Matrix.to_csv(os.path.join(path, \"Matrix_Clean.csv\"), sep=\"\\t\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pyopenms')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edde62aa2661007f0756e9790e7a328c288a583bf6ce768a355147dac67c8db8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
