{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - first column: @p MAP / @p RUN / @p PROTEIN / @p UNASSIGNEDPEPTIDE / @p CONSENSUS / @p PEPTIDE (indicator for the type of data in the current row)\n",
    "  - a @p MAP line contains information about a sub-map; further columns: @p id, @p filename, @p label, @p size (potentially followed by further columns containing meta data, depending on the input)\n",
    "  - a @p CONSENSUS line contains data of a single consensus feature; further columns: @p rt_cf, @p mz_cf, @p intensity_cf, @p charge_cf, @p width_cf, @p quality_cf, @p rt_X0, @p mz_X0, ..., rt_X1, mz_X1, ...\n",
    "  - @p \"..._cf\" columns refer to the consensus feature itself, @p \"..._Xi\" columns refer to a sub-feature from the map with ID \"Xi\" (no @p quality column in this case); missing sub-features are indicated by \"nan\" values\n",
    "  - see above for the formats of @p RUN, @p PROTEIN, @p UNASSIGNEDPEPTIDE, @p PEPTIDE lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Determination of memory status is not supported on this \n",
      " platform, measuring for memoryleaks will never fail\n"
     ]
    }
   ],
   "source": [
    "from pyopenms import *\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureQuantTable(ConsensusMap):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def get_intensity_df(self):\n",
    "        labelfree = self.getExperimentType() == \"label-free\"\n",
    "        filemeta = self.getColumnHeaders()  # type: dict[int, ColumnHeader]\n",
    "        labels = list(set([header.label for header in\n",
    "                           filemeta.values()]))  # TODO could be more efficient. Do we require same channels in all files?\n",
    "        files = list(set([header.filename for header in filemeta.values()]))\n",
    "        label_to_idx = {k: v for v, k in enumerate(labels)}\n",
    "        file_to_idx = {k: v for v, k in enumerate(files)}\n",
    "\n",
    "        def gen(cmap: ConsensusMap, fun):\n",
    "            for f in cmap:\n",
    "                yield from fun(f)\n",
    "\n",
    "        if not labelfree:\n",
    "            # TODO write two functions for LF and labelled. One has only one channel, the other has only one file per CF\n",
    "            def extractRowBlocksChannelWideFileLong(f: ConsensusFeature):\n",
    "                subfeatures = f.getFeatureList()  # type: list[FeatureHandle]\n",
    "                filerows = defaultdict(lambda: [0] * len(labels))  # TODO use numpy array?\n",
    "                for fh in subfeatures:\n",
    "                    header = filemeta[fh.getMapIndex()]\n",
    "                    row = filerows[header.filename]\n",
    "                    row[label_to_idx[header.label]] = fh.getIntensity()\n",
    "                return (f.getUniqueId(), filerows)\n",
    "\n",
    "            def extractRowsChannelWideFileLong(f: ConsensusFeature):\n",
    "                uniqueid, rowdict = extractRowBlocksChannelWideFileLong(f)\n",
    "                for file, row in rowdict.items():\n",
    "                    row.append(file)\n",
    "                    yield tuple([uniqueid] + row)\n",
    "\n",
    "            if len(labels) == 1:\n",
    "                labels[0] = \"intensity\"\n",
    "            dtypes = [('id', np.dtype('uint64'))] + list(zip(labels, ['f'] * len(labels)))\n",
    "            dtypes.append(('file', 'U300'))\n",
    "            # For TMT we know that every feature can only be from one file, since feature = PSM\n",
    "            #cnt = 0\n",
    "            #for f in self:\n",
    "            #    cnt += f.size()\n",
    "\n",
    "            intyarr = np.fromiter(iter=gen(self, extractRowsChannelWideFileLong), dtype=dtypes, count=self.size())\n",
    "            return pd.DataFrame(intyarr).set_index('id')\n",
    "        else:\n",
    "            # Specialized for LabelFree which has to have only one channel\n",
    "            def extractRowBlocksChannelLongFileWideLF(f: ConsensusFeature):\n",
    "                subfeatures = f.getFeatureList()  # type: list[FeatureHandle]\n",
    "                row = [0.] * len(files)  # TODO use numpy array?\n",
    "                for fh in subfeatures:\n",
    "                    header = filemeta[fh.getMapIndex()]\n",
    "                    row[file_to_idx[header.filename]] = fh.getIntensity()\n",
    "                yield tuple([f.getUniqueId()] + row)\n",
    "\n",
    "            dtypes = [('id', np.dtype('uint64'))] + list(zip(files, ['f'] * len(files)))\n",
    "            # cnt = self.size()*len(files) # TODO for this to work, we would need to fill with NAs for CFs that do not go over all files\n",
    "            cnt = self.size()\n",
    "\n",
    "            intyarr = np.fromiter(iter=gen(self, extractRowBlocksChannelLongFileWideLF), dtype=dtypes, count=cnt)\n",
    "            return pd.DataFrame(intyarr).set_index('id')\n",
    "\n",
    "    def get_metadata_df(self):\n",
    "        def gen(cmap: ConsensusMap, fun):\n",
    "            for f in cmap:\n",
    "                yield from fun(f)\n",
    "\n",
    "        def extractMetaData(f: ConsensusFeature):\n",
    "            # subfeatures = f.getFeatureList()  # type: list[FeatureHandle]\n",
    "            pep = f.getPeptideIdentifications()  # type: list[PeptideIdentification]\n",
    "            if len(pep) != 0:\n",
    "                hits = pep[0].getHits()\n",
    "                if len(hits) != 0:\n",
    "                    besthit = hits[0]  # type: PeptideHit\n",
    "                    # TODO what else\n",
    "                    yield f.getUniqueId(), besthit.getSequence().toString(), f.getCharge(), f.getIntensity(), f.getRT(), f.getMZ(), f.getQuality()\n",
    "                else:\n",
    "                    yield f.getUniqueId(), None, f.getCharge(), f.getRT(), f.getIntensity(), f.getMZ(), f.getQuality()\n",
    "            else:\n",
    "                yield f.getUniqueId(), None, f.getCharge(), f.getRT(), f.getIntensity(), f.getMZ(), f.getQuality()\n",
    "\n",
    "        cnt = self.size()\n",
    "\n",
    "        mddtypes = [('id', np.dtype('uint64')), ('sequence', 'U200'), ('charge', 'f'), ('intensity', 'f'), ('RT', 'f'), ('mz', 'f'),\n",
    "                    ('quality', 'f')]\n",
    "        mdarr = np.fromiter(iter=gen(self, extractMetaData), dtype=mddtypes, count=cnt)\n",
    "        return pd.DataFrame(mdarr).set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConsensusXMLFile::store():  found 3544 invalid unique ids\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c_/ysz9v_bd1yb7h3ymmkn6m199jbv7x7/T/ipykernel_11592/394003338.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# get meta data as DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mmeta_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconsensus_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metadata_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# you can concatenate these two for a \"result\" DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/c_/ysz9v_bd1yb7h3ymmkn6m199jbv7x7/T/ipykernel_11592/407358576.py\u001b[0m in \u001b[0;36mget_metadata_df\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m                     ('quality', 'f')]\n\u001b[1;32m     86\u001b[0m         \u001b[0mmdarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromiter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextractMetaData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmddtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmdarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/pyopenms/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0;31m# i.e. numpy structured array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m                 mgr = rec_array_to_mgr(\n\u001b[0m\u001b[1;32m    653\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m                     \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pyopenms/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mrec_array_to_mgr\u001b[0;34m(data, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pyopenms/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_homogenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pyopenms/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_homogenize\u001b[0;34m(data, index, dtype)\u001b[0m\n\u001b[1;32m    587\u001b[0m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_multiget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m             val = sanitize_array(\n\u001b[0m\u001b[1;32m    590\u001b[0m                 \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pyopenms/lib/python3.9/site-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;31m# at this point we should have dtype be None or subarr.dtype == dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sanitize_str_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msubarr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pyopenms/lib/python3.9/site-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36m_sanitize_str_dtypes\u001b[0;34m(result, data, dtype, copy)\u001b[0m\n\u001b[1;32m    656\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_consensus= \"results/consensus/interim/consensus.consensusXML\"\n",
    "cmap = ConsensusMap()\n",
    "ConsensusXMLFile().load(input_consensus, cmap)\n",
    "new_map= ConsensusMap(cmap)\n",
    "new_map.clear(False)\n",
    "for f in cmap:\n",
    "    if f.getPeptideIdentifications() !=[]:\n",
    "        new_map.push_back(f)\n",
    "        \n",
    "Consensus_file= os.path.join(\"results\", \"\", \"consensus\", \"\", 'filtered_pyopenms' + \".consensusXML\")\n",
    "ConsensusXMLFile().store(Consensus_file, new_map)\n",
    "\n",
    "file_descriptions = new_map.getColumnHeaders()\n",
    "\n",
    "consensus_map= ConsensusMapDF()\n",
    "for f in new_map:\n",
    "    consensus_map.push_back(f)\n",
    "    # get intensities as a DataFrame\n",
    "    consensus_map.setColumnHeaders(file_descriptions)\n",
    "\n",
    "    intensities = consensus_map.get_intensity_df()\n",
    "\n",
    "    # get meta data as DataFrame\n",
    "    meta_data = consensus_map.get_metadata_df()\n",
    "\n",
    "    # you can concatenate these two for a \"result\" DataFrame\n",
    "    result = pd.concat([meta_data, intensities], axis=1)\n",
    "\n",
    "    # if you don't need labeled index, remove it (and/or save with index = False)\n",
    "    result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # store as tsv file\n",
    "    result.to_csv('results/consensus/FeatureQuantificationTable.txt', sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TextFile in module pyopenms.pyopenms_3:\n",
      "\n",
      "class TextFile(builtins.object)\n",
      " |  Cython implementation of _TextFile\n",
      " |  \n",
      " |  Documentation is available at http://www.openms.de/current_doxygen/html/classOpenMS_1_1TextFile.html\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __copy__(...)\n",
      " |  \n",
      " |  __deepcopy__(...)\n",
      " |  \n",
      " |  __init__(...)\n",
      " |      - Cython signature: void TextFile()\n",
      " |      - Cython signature: void TextFile(TextFile &)\n",
      " |      - Cython signature: void TextFile(const String & filename, bool trim_linesalse, int first_n1)\n",
      " |  \n",
      " |  __reduce__ = __reduce_cython__(...)\n",
      " |  \n",
      " |  __setstate__ = __setstate_cython__(...)\n",
      " |  \n",
      " |  addLine(...)\n",
      " |      Cython signature: void addLine(const String line)\n",
      " |  \n",
      " |  load(...)\n",
      " |      Cython signature: void load(const String & filename, bool trim_linesalse, int first_n1)\n",
      " |  \n",
      " |  store(...)\n",
      " |      Cython signature: void store(const String & filename)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(TextFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyopenms import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From consensusXML (filtered) to FeatureQuantificationTable.txt\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edde62aa2661007f0756e9790e7a328c288a583bf6ce768a355147dac67c8db8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
