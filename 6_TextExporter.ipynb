{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - first column: @p MAP / @p RUN / @p PROTEIN / @p UNASSIGNEDPEPTIDE / @p CONSENSUS / @p PEPTIDE (indicator for the type of data in the current row)\n",
    "  - a @p MAP line contains information about a sub-map; further columns: @p id, @p filename, @p label, @p size (potentially followed by further columns containing meta data, depending on the input)\n",
    "  - a @p CONSENSUS line contains data of a single consensus feature; further columns: @p rt_cf, @p mz_cf, @p intensity_cf, @p charge_cf, @p width_cf, @p quality_cf, @p rt_X0, @p mz_X0, ..., rt_X1, mz_X1, ...\n",
    "  - @p \"..._cf\" columns refer to the consensus feature itself, @p \"..._Xi\" columns refer to a sub-feature from the map with ID \"Xi\" (no @p quality column in this case); missing sub-features are indicated by \"nan\" values\n",
    "  - see above for the formats of @p RUN, @p PROTEIN, @p UNASSIGNEDPEPTIDE, @p PEPTIDE lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Determination of memory status is not supported on this \n",
      " platform, measuring for memoryleaks will never fail\n"
     ]
    }
   ],
   "source": [
    "from pyopenms import *\n",
    "import pyopenms as pms\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConsensusMapDF(ConsensusMap):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def get_intensity_df(self):\n",
    "        labelfree = self.getExperimentType() == \"label-free\"\n",
    "        filemeta = self.getColumnHeaders()  # type: dict[int, ColumnHeader]\n",
    "        labels = list(set([header.label for header in\n",
    "                           filemeta.values()]))  # TODO could be more efficient. Do we require same channels in all files?\n",
    "        files = list(set([header.filename for header in filemeta.values()]))\n",
    "        label_to_idx = {k: v for v, k in enumerate(labels)}\n",
    "        file_to_idx = {k: v for v, k in enumerate(files)}\n",
    "\n",
    "        def gen(cmap: ConsensusMap, fun):\n",
    "            for f in cmap:\n",
    "                yield from fun(f)\n",
    "\n",
    "        if not labelfree:\n",
    "            # TODO write two functions for LF and labelled. One has only one channel, the other has only one file per CF\n",
    "            def extractRowBlocksChannelWideFileLong(f: ConsensusFeature):\n",
    "                subfeatures = f.getFeatureList()  # type: list[FeatureHandle]\n",
    "                filerows = defaultdict(lambda: [0] * len(labels))  # TODO use numpy array?\n",
    "                for fh in subfeatures:\n",
    "                    header = filemeta[fh.getMapIndex()]\n",
    "                    row = filerows[header.filename]\n",
    "                    row[label_to_idx[header.label]] = fh.getIntensity()\n",
    "                return (f.getUniqueId(), filerows)\n",
    "\n",
    "            def extractRowsChannelWideFileLong(f: ConsensusFeature):\n",
    "                uniqueid, rowdict = extractRowBlocksChannelWideFileLong(f)\n",
    "                for file, row in rowdict.items():\n",
    "                    row.append(file)\n",
    "                    yield tuple([uniqueid] + row)\n",
    "\n",
    "            if len(labels) == 1:\n",
    "                labels[0] = \"intensity\"\n",
    "            dtypes = [('id', np.dtype('uint64'))] + list(zip(labels, ['f'] * len(labels)))\n",
    "            dtypes.append(('file', 'U300'))\n",
    "            # For TMT we know that every feature can only be from one file, since feature = PSM\n",
    "            #cnt = 0\n",
    "            #for f in self:\n",
    "            #    cnt += f.size()\n",
    "\n",
    "            intyarr = np.fromiter(iter=gen(self, extractRowsChannelWideFileLong), dtype=dtypes, count=self.size())\n",
    "            return pd.DataFrame(intyarr).set_index('id')\n",
    "        else:\n",
    "            # Specialized for LabelFree which has to have only one channel\n",
    "            def extractRowBlocksChannelLongFileWideLF(f: ConsensusFeature):\n",
    "                subfeatures = f.getFeatureList()  # type: list[FeatureHandle]\n",
    "                row = [0.] * len(files)  # TODO use numpy array?\n",
    "                for fh in subfeatures:\n",
    "                    header = filemeta[fh.getMapIndex()]\n",
    "                    row[file_to_idx[header.filename]] = fh.getIntensity()\n",
    "                yield tuple([f.getUniqueId()] + row)\n",
    "\n",
    "            dtypes = [('id', np.dtype('uint64'))] + list(zip(files, ['f'] * len(files)))\n",
    "            # cnt = self.size()*len(files) # TODO for this to work, we would need to fill with NAs for CFs that do not go over all files\n",
    "            cnt = self.size()\n",
    "\n",
    "            intyarr = np.fromiter(iter=gen(self, extractRowBlocksChannelLongFileWideLF), dtype=dtypes, count=cnt)\n",
    "            return pd.DataFrame(intyarr).set_index('id')\n",
    "\n",
    "    def get_metadata_df(self):\n",
    "        def gen(cmap: ConsensusMap, fun):\n",
    "            for f in cmap:\n",
    "                yield from fun(f)\n",
    "\n",
    "        def extractMetaData(f: ConsensusFeature):\n",
    "            # subfeatures = f.getFeatureList()  # type: list[FeatureHandle]\n",
    "            pep = f.getPeptideIdentifications()  # type: list[PeptideIdentification]\n",
    "            if len(pep) != 0:\n",
    "                hits = pep[0].getHits()\n",
    "                if len(hits) != 0:\n",
    "                    besthit = hits[0]  # type: PeptideHit\n",
    "                    # TODO what else\n",
    "                    yield f.getUniqueId(), besthit.getSequence().toString(), f.getCharge(), f.getIntensity(), f.getRT(), f.getMZ(), f.getQuality()\n",
    "                else:\n",
    "                    yield f.getUniqueId(), None, f.getCharge(), f.getRT(), f.getIntensity(), f.getMZ(), f.getQuality()\n",
    "            else:\n",
    "                yield f.getUniqueId(), None, f.getCharge(), f.getRT(), f.getIntensity(), f.getMZ(), f.getQuality()\n",
    "\n",
    "        cnt = self.size()\n",
    "\n",
    "        mddtypes = [('id', np.dtype('uint64')), ('sequence', 'U200'), ('charge', 'f'), ('intensity', 'f'), ('RT', 'f'), ('mz', 'f'),\n",
    "                    ('quality', 'f')]\n",
    "        mdarr = np.fromiter(iter=gen(self, extractMetaData), dtype=mddtypes, count=cnt)\n",
    "        return pd.DataFrame(mdarr).set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_consensus= \"results/consensus/interim/consensus.consensusXML\"\n",
    "cmap = ConsensusMap()\n",
    "ConsensusXMLFile().load(input_consensus, cmap)\n",
    "new_map= ConsensusMap(cmap)\n",
    "new_map.clear(False)\n",
    "for f in cmap:\n",
    "    if f.getPeptideIdentifications() !=[]:\n",
    "        new_map.push_back(f)\n",
    "        \n",
    "Consensus_file= os.path.join(\"results\", \"\", \"consensus\", \"\", 'filtered_pyopenms' + \".consensusXML\")\n",
    "ConsensusXMLFile().store(Consensus_file, new_map)\n",
    "\n",
    "file_descriptions = new_map.getColumnHeaders()\n",
    "\n",
    "consensus_map= ConsensusMapDF()\n",
    "for f in new_map:\n",
    "    consensus_map.push_back(f)\n",
    "    # get intensities as a DataFrame\n",
    "    consensus_map.setColumnHeaders(file_descriptions)\n",
    "\n",
    "    intensities = consensus_map.get_intensity_df()\n",
    "\n",
    "    # get meta data as DataFrame\n",
    "    meta_data = consensus_map.get_metadata_df()\n",
    "\n",
    "    # you can concatenate these two for a \"result\" DataFrame\n",
    "    result = pd.concat([meta_data, intensities], axis=1)\n",
    "\n",
    "    # if you don't need labeled index, remove it (and/or save with index = False)\n",
    "    result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # store as tsv file\n",
    "    result.to_csv('results/consensus/FeatureQuantificationTable.txt', sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TextFile in module pyopenms.pyopenms_3:\n",
      "\n",
      "class TextFile(builtins.object)\n",
      " |  Cython implementation of _TextFile\n",
      " |  \n",
      " |  Documentation is available at http://www.openms.de/current_doxygen/html/classOpenMS_1_1TextFile.html\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __copy__(...)\n",
      " |  \n",
      " |  __deepcopy__(...)\n",
      " |  \n",
      " |  __init__(...)\n",
      " |      - Cython signature: void TextFile()\n",
      " |      - Cython signature: void TextFile(TextFile &)\n",
      " |      - Cython signature: void TextFile(const String & filename, bool trim_linesalse, int first_n1)\n",
      " |  \n",
      " |  __reduce__ = __reduce_cython__(...)\n",
      " |  \n",
      " |  __setstate__ = __setstate_cython__(...)\n",
      " |  \n",
      " |  addLine(...)\n",
      " |      Cython signature: void addLine(const String line)\n",
      " |  \n",
      " |  load(...)\n",
      " |      Cython signature: void load(const String & filename, bool trim_linesalse, int first_n1)\n",
      " |  \n",
      " |  store(...)\n",
      " |      Cython signature: void store(const String & filename)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(TextFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edde62aa2661007f0756e9790e7a328c288a583bf6ce768a355147dac67c8db8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
